{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentiRoBERTa\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we will use NLTK's twitter dataset and along  the `distilroberta-base` model checkpoint to train `sentiroberta` for sentiment classification.\n",
    "\n",
    "- Requirements\n",
    "  - transformers\n",
    "  - datasets (hugging-face)\n",
    "  - pytorch\n",
    "  - numpy\n",
    "  - NLTK\n",
    " \n",
    "  \n",
    "- The `datasets` library abstracts many of the pre-processing steps, so we get right into building our model as fast as possible.  \n",
    "\n",
    "> ***TIP:*** *If you are new to programming or new to NLP, I still suggest doing the manual steps - including re-inventing the wheel. Start with the `text-cleaning -> tokenization -> extracting-features` and finally modeling because all of these steps affect the final result. Consequently, there are infinite blends and specific techniques in an NLP pipeline; choosing the most suitable requires knowing what not to do!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.jupyter import print\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "def twitter_dataset(\n",
    "    ratio=1.0,\n",
    "    size=5000,\n",
    "    format='dataset',\n",
    "    labels_dtype='list',\n",
    "    columns=['texts', 'labels'],\n",
    "):\n",
    "    \"\"\"Twitter Dataset\n",
    "    :param format: a type of data format; `dataset` or `mapped`.\n",
    "    :param labels_dtype: labels data type; `np` or `list`.\n",
    "    \"\"\"\n",
    "    A, B = columns\n",
    "    pos = twitter_samples.strings('positive_tweets.json')[:size]\n",
    "    neg = twitter_samples.strings('negative_tweets.json')[:size]\n",
    "    k = int(ratio * size)\n",
    "    x_tweets = pos[:k] + neg[:k]  # Train text splits.\n",
    "    y_tweets = pos[k:] + neg[k:]  # Test text splits.\n",
    "    x_labels = [1] * len(pos[:k]) + [0] * len(neg[:k])\n",
    "    y_labels = [1] * len(pos[k:]) + [0] * len(neg[k:])\n",
    "    if format in 'mapped':\n",
    "        tweets = x_tweets + y_tweets\n",
    "        labels = x_labels + y_labels\n",
    "        if labels_dtype == 'np':\n",
    "            labels = np.array(labels)[None, :].T\n",
    "        return {A: tweets, B: labels}\n",
    "    dataset = {}\n",
    "    if labels_dtype == 'np':\n",
    "        x_labels = np.array(x_labels)[None, :].T\n",
    "        y_labels = np.array(y_labels)[None, :].T\n",
    "    dataset['x'] = {A: x_tweets, B: x_labels}\n",
    "    dataset['y'] = {A: y_tweets, B: y_labels}\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">DatasetDict<span style=\"font-weight: bold\">({</span>\n",
       "    train: Dataset<span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'text'</span>, <span style=\"color: #008000\">'labels'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #000080; font-weight: bold\">9000</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "    test: Dataset<span style=\"font-weight: bold\">({</span>\n",
       "        features: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'text'</span>, <span style=\"color: #008000\">'labels'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        num_rows: <span style=\"color: #000080; font-weight: bold\">1000</span>\n",
       "    <span style=\"font-weight: bold\">})</span>\n",
       "<span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efdaeb90d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.Dataset.from_dict(\n",
    "    mapping=twitter_dataset(format='mapped', columns=['text', 'labels']),\n",
    "    split=['train', 'test'],\n",
    ")\n",
    "dataset_split = dataset.train_test_split(0.1, shuffle=True, seed=1234)\n",
    "print(dataset_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('distilroberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1659f97e9a9480f9fbc3b162b22ceb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2ce53147b04fe180999ccf01419311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_seqlen = 64\n",
    "encoded_dataset = dataset_split.map(\n",
    "    lambda field: tokenizer(\n",
    "        field['text'], padding=True, truncation=True, max_length=max_seqlen,\n",
    "    ), batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">input_ids: torch.Size<span style=\"font-weight: bold\">([</span><span style=\"color: #000080; font-weight: bold\">64</span><span style=\"font-weight: bold\">])</span>, label_class: torch.Size<span style=\"font-weight: bold\">([</span><span style=\"color: #000080; font-weight: bold\">9000</span><span style=\"font-weight: bold\">])</span>\n",
       "* <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'train'</span>, <span style=\"color: #008000\">'test'</span><span style=\"font-weight: bold\">]</span>\n",
       "         - <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'attention_mask'</span>, <span style=\"color: #008000\">'input_ids'</span>, <span style=\"color: #008000\">'labels'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efd941e0190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = list(encoded_dataset['train'][0].keys())\n",
    "if 'text' in columns:\n",
    "    columns.pop(columns.index('text'))\n",
    "\n",
    "encoded_dataset.set_format(type='torch', columns=columns)\n",
    "print('input_ids: {}, label_class: {}\\n* {}\\n\\t - {}'.format(\n",
    "    encoded_dataset['train']['input_ids'][0].shape,\n",
    "    encoded_dataset['train']['labels'].shape,\n",
    "    list(encoded_dataset.column_names),\n",
    "    columns,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000\">'attention_mask'</span>: tensor<span style=\"font-weight: bold\">([[</span><span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>,\n",
       "<span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]])</span>,\n",
       "    <span style=\"color: #008000\">'input_ids'</span>: tensor<span style=\"font-weight: bold\">([[</span>    <span style=\"color: #000080; font-weight: bold\">0</span>,   <span style=\"color: #000080; font-weight: bold\">100</span>, <span style=\"color: #000080; font-weight: bold\">23126</span>,  <span style=\"color: #000080; font-weight: bold\">1183</span>, <span style=\"color: #000080; font-weight: bold\">13102</span>,  <span style=\"color: #000080; font-weight: bold\">2399</span>,  <span style=\"color: #000080; font-weight: bold\">3355</span>,   <span style=\"color: #000080; font-weight: bold\">456</span>, <span style=\"color: #000080; font-weight: bold\">46225</span>,     \n",
       "<span style=\"color: #000080; font-weight: bold\">2</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>    <span style=\"color: #000080; font-weight: bold\">0</span>,  <span style=\"color: #000080; font-weight: bold\">9502</span>,    <span style=\"color: #000080; font-weight: bold\">86</span>,     <span style=\"color: #000080; font-weight: bold\">7</span>,   <span style=\"color: #000080; font-weight: bold\">213</span>,     <span style=\"color: #000080; font-weight: bold\">7</span>,   <span style=\"color: #000080; font-weight: bold\">334</span>,   <span style=\"color: #000080; font-weight: bold\">396</span>,   <span style=\"color: #000080; font-weight: bold\">127</span>, <span style=\"color: #000080; font-weight: bold\">15641</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">10219</span>,  <span style=\"color: #000080; font-weight: bold\">4832</span>, <span style=\"color: #000080; font-weight: bold\">48461</span>,    <span style=\"color: #000080; font-weight: bold\">24</span>,  <span style=\"color: #000080; font-weight: bold\">2653</span>,  <span style=\"color: #000080; font-weight: bold\">8372</span>,     <span style=\"color: #000080; font-weight: bold\">2</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>    <span style=\"color: #000080; font-weight: bold\">0</span>,  <span style=\"color: #000080; font-weight: bold\">1039</span>,   <span style=\"color: #000080; font-weight: bold\">495</span>,  <span style=\"color: #000080; font-weight: bold\">1584</span>,  <span style=\"color: #000080; font-weight: bold\">1090</span>, <span style=\"color: #000080; font-weight: bold\">12083</span>, <span style=\"color: #000080; font-weight: bold\">46116</span>,    <span style=\"color: #000080; font-weight: bold\">38</span>,  <span style=\"color: #000080; font-weight: bold\">4443</span>,    <span style=\"color: #000080; font-weight: bold\">38</span>,\n",
       "           <span style=\"color: #000080; font-weight: bold\">437</span>,    <span style=\"color: #000080; font-weight: bold\">45</span>,    <span style=\"color: #000080; font-weight: bold\">10</span>,   <span style=\"color: #000080; font-weight: bold\">569</span>,   <span style=\"color: #000080; font-weight: bold\">177</span>, <span style=\"color: #000080; font-weight: bold\">39547</span>,     <span style=\"color: #000080; font-weight: bold\">4</span>,    <span style=\"color: #000080; font-weight: bold\">38</span>,   <span style=\"color: #000080; font-weight: bold\">109</span>,   <span style=\"color: #000080; font-weight: bold\">101</span>,\n",
       "          <span style=\"color: #000080; font-weight: bold\">4845</span>, <span style=\"color: #000080; font-weight: bold\">32232</span>,   <span style=\"color: #000080; font-weight: bold\">272</span>,  <span style=\"color: #000080; font-weight: bold\">1253</span>,   <span style=\"color: #000080; font-weight: bold\">108</span>,    <span style=\"color: #000080; font-weight: bold\">97</span>,  <span style=\"color: #000080; font-weight: bold\">3541</span>,   <span style=\"color: #000080; font-weight: bold\">600</span>,   <span style=\"color: #000080; font-weight: bold\">111</span>,  <span style=\"color: #000080; font-weight: bold\">1649</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">19767</span>,     <span style=\"color: #000080; font-weight: bold\">9</span>,     <span style=\"color: #000080; font-weight: bold\">5</span>,  <span style=\"color: #000080; font-weight: bold\">7602</span>,    <span style=\"color: #000080; font-weight: bold\">66</span>, <span style=\"color: #000080; font-weight: bold\">44660</span>,     <span style=\"color: #000080; font-weight: bold\">2</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>    <span style=\"color: #000080; font-weight: bold\">0</span>,  <span style=\"color: #000080; font-weight: bold\">1039</span>, <span style=\"color: #000080; font-weight: bold\">20770</span>, <span style=\"color: #000080; font-weight: bold\">40941</span>, <span style=\"color: #000080; font-weight: bold\">21446</span>,  <span style=\"color: #000080; font-weight: bold\">1215</span>,    <span style=\"color: #000080; font-weight: bold\">38</span>,  <span style=\"color: #000080; font-weight: bold\">2220</span>,    <span style=\"color: #000080; font-weight: bold\">75</span>,   <span style=\"color: #000080; font-weight: bold\">190</span>,\n",
       "          <span style=\"color: #000080; font-weight: bold\">3996</span>,   <span style=\"color: #000080; font-weight: bold\">143</span>,    <span style=\"color: #000080; font-weight: bold\">24</span>,    <span style=\"color: #000080; font-weight: bold\">95</span>, <span style=\"color: #000080; font-weight: bold\">17796</span>, <span style=\"color: #000080; font-weight: bold\">11365</span>,    <span style=\"color: #000080; font-weight: bold\">31</span>, <span style=\"color: #000080; font-weight: bold\">10242</span>,     <span style=\"color: #000080; font-weight: bold\">4</span>, <span style=\"color: #000080; font-weight: bold\">26029</span>,\n",
       "         <span style=\"color: #000080; font-weight: bold\">46225</span>,     <span style=\"color: #000080; font-weight: bold\">2</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>    <span style=\"color: #000080; font-weight: bold\">0</span>,   <span style=\"color: #000080; font-weight: bold\">118</span>, <span style=\"color: #000080; font-weight: bold\">23523</span>,  <span style=\"color: #000080; font-weight: bold\">3369</span>, <span style=\"color: #000080; font-weight: bold\">12198</span>,   <span style=\"color: #000080; font-weight: bold\">123</span>,     <span style=\"color: #000080; font-weight: bold\">9</span>, <span style=\"color: #000080; font-weight: bold\">44660</span>,     <span style=\"color: #000080; font-weight: bold\">2</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>    <span style=\"color: #000080; font-weight: bold\">0</span>,   <span style=\"color: #000080; font-weight: bold\">415</span>,    <span style=\"color: #000080; font-weight: bold\">78</span>,    <span style=\"color: #000080; font-weight: bold\">38</span>,   <span style=\"color: #000080; font-weight: bold\">222</span>,   <span style=\"color: #000080; font-weight: bold\">657</span>,    <span style=\"color: #000080; font-weight: bold\">47</span>,     <span style=\"color: #000080; font-weight: bold\">6</span>,    <span style=\"color: #000080; font-weight: bold\">53</span>,   <span style=\"color: #000080; font-weight: bold\">122</span>,\n",
       "            <span style=\"color: #000080; font-weight: bold\">38</span>,    <span style=\"color: #000080; font-weight: bold\">95</span>, <span style=\"color: #000080; font-weight: bold\">23126</span>, <span style=\"color: #000080; font-weight: bold\">26536</span>,     <span style=\"color: #000080; font-weight: bold\">6</span>,   <span style=\"color: #000080; font-weight: bold\">628</span>,   <span style=\"color: #000080; font-weight: bold\">363</span>,  <span style=\"color: #000080; font-weight: bold\">2053</span>,     <span style=\"color: #000080; font-weight: bold\">9</span>,    <span style=\"color: #000080; font-weight: bold\">47</span>,\n",
       "           <span style=\"color: #000080; font-weight: bold\">454</span>,    <span style=\"color: #000080; font-weight: bold\">38</span>,   <span style=\"color: #000080; font-weight: bold\">300</span>,    <span style=\"color: #000080; font-weight: bold\">10</span>, <span style=\"color: #000080; font-weight: bold\">17145</span>, <span style=\"color: #000080; font-weight: bold\">48433</span>,  <span style=\"color: #000080; font-weight: bold\">4832</span>,   <span style=\"color: #000080; font-weight: bold\">705</span>, <span style=\"color: #000080; font-weight: bold\">50118</span>, <span style=\"color: #000080; font-weight: bold\">50118</span>,\n",
       "           <span style=\"color: #000080; font-weight: bold\">113</span>, <span style=\"color: #000080; font-weight: bold\">13724</span>,   <span style=\"color: #000080; font-weight: bold\">734</span>,  <span style=\"color: #000080; font-weight: bold\">2054</span>,   <span style=\"color: #000080; font-weight: bold\">640</span>,    <span style=\"color: #000080; font-weight: bold\">90</span>,     <span style=\"color: #000080; font-weight: bold\">4</span>,   <span style=\"color: #000080; font-weight: bold\">876</span>,    <span style=\"color: #000080; font-weight: bold\">73</span>,   <span style=\"color: #000080; font-weight: bold\">398</span>,\n",
       "           <span style=\"color: #000080; font-weight: bold\">975</span>,   <span style=\"color: #000080; font-weight: bold\">298</span>,   <span style=\"color: #000080; font-weight: bold\">574</span>, <span style=\"color: #000080; font-weight: bold\">38133</span>,  <span style=\"color: #000080; font-weight: bold\">1549</span>,   <span style=\"color: #000080; font-weight: bold\">574</span>,   <span style=\"color: #000080; font-weight: bold\">506</span>,     <span style=\"color: #000080; font-weight: bold\">2</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>    <span style=\"color: #000080; font-weight: bold\">0</span>,  <span style=\"color: #000080; font-weight: bold\">2387</span>,    <span style=\"color: #000080; font-weight: bold\">94</span>,   <span style=\"color: #000080; font-weight: bold\">183</span>,    <span style=\"color: #000080; font-weight: bold\">11</span>,  <span style=\"color: #000080; font-weight: bold\">4552</span>,  <span style=\"color: #000080; font-weight: bold\">4832</span>, <span style=\"color: #000080; font-weight: bold\">48461</span>, <span style=\"color: #000080; font-weight: bold\">48461</span>,     <span style=\"color: #000080; font-weight: bold\">2</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>    <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">21136</span>,   <span style=\"color: #000080; font-weight: bold\">273</span>,    <span style=\"color: #000080; font-weight: bold\">47</span>, <span style=\"color: #000080; font-weight: bold\">28651</span>,    <span style=\"color: #000080; font-weight: bold\">29</span>,   <span style=\"color: #000080; font-weight: bold\">328</span>, <span style=\"color: #000080; font-weight: bold\">44660</span>, <span style=\"color: #000080; font-weight: bold\">29293</span>, <span style=\"color: #000080; font-weight: bold\">11582</span>,\n",
       "           <span style=\"color: #000080; font-weight: bold\">849</span>,  <span style=\"color: #000080; font-weight: bold\">7389</span>,   <span style=\"color: #000080; font-weight: bold\">787</span>,    <span style=\"color: #000080; font-weight: bold\">29</span>,  <span style=\"color: #000080; font-weight: bold\">6673</span>,   <span style=\"color: #000080; font-weight: bold\">324</span>,  <span style=\"color: #000080; font-weight: bold\">2544</span>, <span style=\"color: #000080; font-weight: bold\">33017</span>,   <span style=\"color: #000080; font-weight: bold\">787</span>,   <span style=\"color: #000080; font-weight: bold\">438</span>,\n",
       "           <span style=\"color: #000080; font-weight: bold\">877</span>,   <span style=\"color: #000080; font-weight: bold\">438</span>,  <span style=\"color: #000080; font-weight: bold\">1584</span>,   <span style=\"color: #000080; font-weight: bold\">607</span>,   <span style=\"color: #000080; font-weight: bold\">787</span>, <span style=\"color: #000080; font-weight: bold\">27693</span>,  <span style=\"color: #000080; font-weight: bold\">1215</span>, <span style=\"color: #000080; font-weight: bold\">11428</span>,  <span style=\"color: #000080; font-weight: bold\">1594</span>,  <span style=\"color: #000080; font-weight: bold\">1054</span>,\n",
       "          <span style=\"color: #000080; font-weight: bold\">5479</span>,  <span style=\"color: #000080; font-weight: bold\">1437</span>,   <span style=\"color: #000080; font-weight: bold\">787</span>,   <span style=\"color: #000080; font-weight: bold\">267</span>, <span style=\"color: #000080; font-weight: bold\">16836</span>,  <span style=\"color: #000080; font-weight: bold\">3863</span>,  <span style=\"color: #000080; font-weight: bold\">4297</span>,  <span style=\"color: #000080; font-weight: bold\">1334</span>,  <span style=\"color: #000080; font-weight: bold\">4825</span>,  <span style=\"color: #000080; font-weight: bold\">1437</span>,\n",
       "           <span style=\"color: #000080; font-weight: bold\">787</span>, <span style=\"color: #000080; font-weight: bold\">34537</span>,  <span style=\"color: #000080; font-weight: bold\">2401</span>,   <span style=\"color: #000080; font-weight: bold\">261</span>,  <span style=\"color: #000080; font-weight: bold\">1215</span>,  <span style=\"color: #000080; font-weight: bold\">2054</span>,   <span style=\"color: #000080; font-weight: bold\">640</span>,    <span style=\"color: #000080; font-weight: bold\">90</span>,     <span style=\"color: #000080; font-weight: bold\">4</span>,   <span style=\"color: #000080; font-weight: bold\">876</span>,\n",
       "            <span style=\"color: #000080; font-weight: bold\">73</span>,   <span style=\"color: #000080; font-weight: bold\">102</span>, <span style=\"color: #000080; font-weight: bold\">40528</span>,   <span style=\"color: #000080; font-weight: bold\">250</span>,   <span style=\"color: #000080; font-weight: bold\">246</span>,   <span style=\"color: #000080; font-weight: bold\">725</span>,   <span style=\"color: #000080; font-weight: bold\">406</span>, <span style=\"color: #000080; font-weight: bold\">19996</span>,     <span style=\"color: #000080; font-weight: bold\">2</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,\n",
       "             <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span>,     <span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]])</span>,\n",
       "    <span style=\"color: #008000\">'labels'</span>: tensor<span style=\"font-weight: bold\">([</span><span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">0</span>, <span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efd9217a0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dl = DataLoader(encoded_dataset['test'], batch_size=8)\n",
    "input_batch = next(iter(test_dl))\n",
    "print(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">RobertaForSequenceClassification<span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>roberta<span style=\"font-weight: bold\">)</span>: RobertaModel<span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>embeddings<span style=\"font-weight: bold\">)</span>: RobertaEmbeddings<span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"font-weight: bold\">(</span>word_embeddings<span style=\"font-weight: bold\">)</span>: Embedding<span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">50265</span>, <span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">padding_idx</span>=<span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span>position_embeddings<span style=\"font-weight: bold\">)</span>: Embedding<span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">514</span>, <span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">padding_idx</span>=<span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span>token_type_embeddings<span style=\"font-weight: bold\">)</span>: Embedding<span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">1</span>, <span style=\"color: #000080; font-weight: bold\">768</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>encoder<span style=\"font-weight: bold\">)</span>: RobertaEncoder<span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"font-weight: bold\">(</span>layer<span style=\"font-weight: bold\">)</span>: ModuleList<span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>: RobertaLayer<span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>attention<span style=\"font-weight: bold\">)</span>: RobertaAttention<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>self<span style=\"font-weight: bold\">)</span>: RobertaSelfAttention<span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>query<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>key<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>value<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: RobertaSelfOutput<span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>intermediate<span style=\"font-weight: bold\">)</span>: RobertaIntermediate<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">3072</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: RobertaOutput<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">3072</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: RobertaLayer<span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>attention<span style=\"font-weight: bold\">)</span>: RobertaAttention<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>self<span style=\"font-weight: bold\">)</span>: RobertaSelfAttention<span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>query<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>key<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>value<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: RobertaSelfOutput<span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>intermediate<span style=\"font-weight: bold\">)</span>: RobertaIntermediate<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">3072</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: RobertaOutput<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">3072</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>: RobertaLayer<span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>attention<span style=\"font-weight: bold\">)</span>: RobertaAttention<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>self<span style=\"font-weight: bold\">)</span>: RobertaSelfAttention<span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>query<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>key<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>value<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: RobertaSelfOutput<span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>intermediate<span style=\"font-weight: bold\">)</span>: RobertaIntermediate<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">3072</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: RobertaOutput<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">3072</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>: RobertaLayer<span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>attention<span style=\"font-weight: bold\">)</span>: RobertaAttention<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>self<span style=\"font-weight: bold\">)</span>: RobertaSelfAttention<span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>query<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>key<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>value<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: RobertaSelfOutput<span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>intermediate<span style=\"font-weight: bold\">)</span>: RobertaIntermediate<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">3072</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: RobertaOutput<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">3072</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span>: RobertaLayer<span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>attention<span style=\"font-weight: bold\">)</span>: RobertaAttention<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>self<span style=\"font-weight: bold\">)</span>: RobertaSelfAttention<span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>query<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>key<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>value<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: RobertaSelfOutput<span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>intermediate<span style=\"font-weight: bold\">)</span>: RobertaIntermediate<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">3072</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: RobertaOutput<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">3072</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>: RobertaLayer<span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>attention<span style=\"font-weight: bold\">)</span>: RobertaAttention<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>self<span style=\"font-weight: bold\">)</span>: RobertaSelfAttention<span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>query<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>key<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>value<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: RobertaSelfOutput<span style=\"font-weight: bold\">(</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "              <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>intermediate<span style=\"font-weight: bold\">)</span>: RobertaIntermediate<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">3072</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>output<span style=\"font-weight: bold\">)</span>: RobertaOutput<span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">3072</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>LayerNorm<span style=\"font-weight: bold\">)</span>: LayerNorm<span style=\"font-weight: bold\">((</span><span style=\"color: #000080; font-weight: bold\">768</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000\">eps</span>=<span style=\"color: #000080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>classifier<span style=\"font-weight: bold\">)</span>: RobertaClassificationHead<span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>dense<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: Dropout<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">p</span>=<span style=\"color: #000080; font-weight: bold\">0.1</span>, <span style=\"color: #808000\">inplace</span>=<span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>out_proj<span style=\"font-weight: bold\">)</span>: Linear<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">in_features</span>=<span style=\"color: #000080; font-weight: bold\">768</span>, <span style=\"color: #808000\">out_features</span>=<span style=\"color: #000080; font-weight: bold\">2</span>, <span style=\"color: #808000\">bias</span>=<span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efd94112490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    'distilroberta-base', return_dict=True\n",
    ")\n",
    "model = model.train()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">0.6575</span>, <span style=\"color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; font-weight: bold\">NllLossBackward</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efd92360410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = input_batch['labels']\n",
    "inputs = input_batch['input_ids']\n",
    "attention_mask = input_batch['attention_mask']\n",
    "outputs = model(inputs, attention_mask=attention_mask)\n",
    "loss = F.cross_entropy(outputs.logits, labels)\n",
    "loss.backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Metric<span style=\"font-weight: bold\">(</span>name: <span style=\"color: #008000\">\"accuracy\"</span>, features: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'predictions'</span>: Value<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">dtype</span>=<span style=\"color: #008000\">'int32'</span>, <span style=\"color: #808000\">id</span>=<span style=\"color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"color: #008000\">'references'</span>: Value<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">dtype</span>=<span style=\"color: #008000\">'int32'</span>, <span style=\"color: #808000\">id</span>=<span style=\"color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)}</span>, usage: <span style=\"color: #008000\">\"\"</span>\"\n",
       "Args:\n",
       "    predictions: Predicted labels, as returned by a model.\n",
       "    references: Ground truth labels.\n",
       "    normalize: If <span style=\"color: #ff0000; font-style: italic\">False</span>, return the number of correctly classified samples.\n",
       "        Otherwise, return the fraction of correctly classified samples.\n",
       "    sample_weight: Sample weights.\n",
       "Returns:\n",
       "    accuracy: Accuracy score.\n",
       "<span style=\"color: #008000\">\"\"</span>\", stored examples: <span style=\"color: #000080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efd9230fad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glue_task = \"accuracy\"\n",
    "metric = datasets.load_metric(glue_task)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'accuracy'</span>: <span style=\"color: #000080; font-weight: bold\">0.75</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efd92319d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "def model_init():\n",
    "    return RobertaForSequenceClassification.from_pretrained(\n",
    "        'distilroberta-base', return_dict=True,\n",
    "    )\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = preds.argmax(axis=-1)\n",
    "    return metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "# Test function before training session!\n",
    "print(compute_metrics((outputs.logits, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model  # Delete the current initialized model we used to test the DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='SentiRoBERTa',\n",
    "    overwrite_output_dir=True,\n",
    "    eval_accumulation_steps=True,\n",
    "    eval_steps=500,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    disable_tqdm=False,\n",
    "    fp16=True,  # set scaled floating point.\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=encoded_dataset['train'],\n",
    "    eval_dataset=encoded_dataset['test'],\n",
    "    model_init=model_init,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hyperparameter search docs**\n",
    "\n",
    "- Args\n",
    "\n",
    "  - **compute_objective** (:obj:`Callable[[Dict[str, float]], float]`, `optional`):\n",
    "  \n",
    "    - A function computing the objective to minimize or maximize from the metrics returned by the :obj:`evaluate` method. Will default to :func:`~transformers.trainer_utils.default_compute_objective`.\n",
    " \n",
    "  - **n_trials** (:obj:`int`, `optional`, defaults to 100):\n",
    "  \n",
    "    - The number of trial runs to test.\n",
    "    \n",
    "  - **direction** (:obj:`str`, `optional`, defaults to :obj:`\"minimize\"`):\n",
    " \n",
    "    - Whether to optimize greater or lower objects. Can be :obj:`\"minimize\"` or :obj:`\"maximize\"`, you should pick :obj:`\"minimize\"` when optimizing the validation loss, :obj:`\"maximize\"` when optimizing one or several metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-20 00:45:33,024]\u001b[0m A new study created in memory with name: no-name-f344b652-bbc3-4e1b-ba3a-738b78b3e87a\u001b[0m\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2250/2250 03:01, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.332500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1375' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 1:09:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-20 00:48:43,947]\u001b[0m Trial 0 finished with value: 284.1903 and parameters: {'learning_rate': 2.015492944525841e-06, 'num_train_epochs': 2, 'seed': 5, 'per_device_train_batch_size': 8}. Best is trial 0 with value: 284.1903.\u001b[0m\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1128' max='1128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1128/1128 03:57, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.001400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-20 00:52:50,941]\u001b[0m Trial 1 finished with value: 279.0453 and parameters: {'learning_rate': 6.716647183348325e-05, 'num_train_epochs': 4, 'seed': 26, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 284.1903.\u001b[0m\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2250/2250 03:04, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-20 00:56:04,454]\u001b[0m Trial 2 finished with value: 278.921 and parameters: {'learning_rate': 2.4252538182599025e-05, 'num_train_epochs': 2, 'seed': 29, 'per_device_train_batch_size': 8}. Best is trial 0 with value: 284.1903.\u001b[0m\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [141/141 00:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-20 00:57:07,112]\u001b[0m Trial 3 finished with value: 241.8805 and parameters: {'learning_rate': 1.659903578537249e-05, 'num_train_epochs': 1, 'seed': 33, 'per_device_train_batch_size': 64}. Best is trial 0 with value: 284.1903.\u001b[0m\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1126' max='1126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1126/1126 02:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-20 00:59:46,511]\u001b[0m Trial 4 finished with value: 262.1658 and parameters: {'learning_rate': 1.9593029202139164e-05, 'num_train_epochs': 2, 'seed': 28, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 284.1903.\u001b[0m\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='11250' max='11250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11250/11250 12:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.049200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.014100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-20 01:12:36,909]\u001b[0m Trial 5 finished with value: 276.2296 and parameters: {'learning_rate': 3.566022862064323e-05, 'num_train_epochs': 5, 'seed': 3, 'per_device_train_batch_size': 4}. Best is trial 0 with value: 284.1903.\u001b[0m\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [564/564 03:29, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.033600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-20 01:16:15,444]\u001b[0m Trial 6 finished with value: 278.5786 and parameters: {'learning_rate': 1.8779524995389454e-05, 'num_train_epochs': 4, 'seed': 3, 'per_device_train_batch_size': 64}. Best is trial 0 with value: 284.1903.\u001b[0m\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='9000' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9000/9000 09:41, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.041800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.027300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.009700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-20 01:26:06,308]\u001b[0m Trial 7 finished with value: 281.5795 and parameters: {'learning_rate': 9.007294721770037e-05, 'num_train_epochs': 4, 'seed': 32, 'per_device_train_batch_size': 4}. Best is trial 0 with value: 284.1903.\u001b[0m\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='846' max='846' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [846/846 03:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.245200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-20 01:29:16,766]\u001b[0m Trial 8 finished with value: 279.3541 and parameters: {'learning_rate': 1.901440320007455e-06, 'num_train_epochs': 3, 'seed': 26, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 284.1903.\u001b[0m\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1125' max='1125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1125/1125 01:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.031400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.018700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-20 01:31:00,154]\u001b[0m Trial 9 finished with value: 266.868 and parameters: {'learning_rate': 9.38030078656833e-05, 'num_train_epochs': 1, 'seed': 13, 'per_device_train_batch_size': 8}. Best is trial 0 with value: 284.1903.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_run = trainer.hyperparameter_search(\n",
    "    direction='maximize',  # We want to optimize our accuracy metric (classification)\n",
    "    backend='optuna',  # Check transformers docs for other supported backends.\n",
    "    n_trials=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">BestRun<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">run_id</span>=<span style=\"color: #008000\">'0'</span>, <span style=\"color: #808000\">objective</span>=<span style=\"color: #000080; font-weight: bold\">284.1903</span>, <span style=\"color: #808000\">hyperparameters</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'learning_rate'</span>: \n",
       "<span style=\"color: #000080; font-weight: bold\">2.015492944525841e-06</span>, <span style=\"color: #008000\">'num_train_epochs'</span>: <span style=\"color: #000080; font-weight: bold\">2</span>, <span style=\"color: #008000\">'seed'</span>: <span style=\"color: #000080; font-weight: bold\">5</span>, <span style=\"color: #008000\">'per_device_train_batch_size'</span>: <span style=\"color: #000080; font-weight: bold\">8</span><span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efce58d9750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(best_run)  # Our final best run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with optimized Hyperparameters\n",
    "\n",
    "The `trainer.train()` method will take care of everything for us! But to give you an idea of what is going on in the background see the code below.\n",
    "\n",
    "```python\n",
    "# out optimized optuna parameters\n",
    "optuna_lr = 2.015492944525841e-06\n",
    "optuna_epochs = 2\n",
    "\n",
    "dataloader = Dataloader(...)  # train and eval loaders\n",
    "optimizer = AdamW(model.parameters(), lr=optuna_lr)\n",
    "\n",
    "for epoch in range(optuna_epochs):\n",
    "    for batch in dataloader:\n",
    "        optim.zero_grad()\n",
    "        input = batch[\"input_ids\"].to(device)\n",
    "        attn_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        output = model(input, attention_mask=attn_mask, labels=labels)\n",
    "        loss = output[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2250/2250 03:02, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.331900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2250, training_loss=0.07920986966954337, metrics={'train_runtime': 182.4037, 'train_samples_per_second': 12.335, 'total_flos': 567613011456000, 'epoch': 2.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets use the optimized hyperparameters for training our sentiment-model.\n",
    "for n, v in best_run.hyperparameters.items():\n",
    "    setattr(trainer.args, n, v)  # override the previous training arguments.\n",
    "\n",
    "trainer.train()  # Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000\">'eval_loss'</span>: <span style=\"color: #000080; font-weight: bold\">0.013734864071011543</span>,\n",
       "    <span style=\"color: #008000\">'eval_accuracy'</span>: <span style=\"color: #000080; font-weight: bold\">0.998</span>,\n",
       "    <span style=\"color: #008000\">'eval_runtime'</span>: <span style=\"color: #000080; font-weight: bold\">3.8846</span>,\n",
       "    <span style=\"color: #008000\">'eval_samples_per_second'</span>: <span style=\"color: #000080; font-weight: bold\">257.428</span>,\n",
       "    <span style=\"color: #008000\">'epoch'</span>: <span style=\"color: #000080; font-weight: bold\">2.0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efce42d42d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wow that was fast!\n",
    "print(trainer.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sentiroberta/pt/tokenizer_config.json',\n",
       " 'sentiroberta/pt/special_tokens_map.json',\n",
       " 'sentiroberta/pt/vocab.json',\n",
       " 'sentiroberta/pt/merges.txt',\n",
       " 'sentiroberta/pt/added_tokens.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer.\n",
    "trainer.save_model('sentiroberta/pt')\n",
    "trainer.tokenizer.save_pretrained('sentiroberta/pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify and load the saved model and tokenizer\n",
    "model = RobertaForSequenceClassification.from_pretrained('sentiroberta/pt/')\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('sentiroberta/pt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# We will use the existing sentiment pipeline to test our model with actual text,\n",
    "model.config.id2label.update({0: 'NEGATIVE', 1: 'POSITIVE'}) \n",
    "# Simply pass the Model and Tokenizer to the pipe.\n",
    "sentiment = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[{</span><span style=\"color: #008000\">'label'</span>: <span style=\"color: #008000\">'NEGATIVE'</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9998264908790588</span><span style=\"font-weight: bold\">}]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efcbfa9bdd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[{</span><span style=\"color: #008000\">'label'</span>: <span style=\"color: #008000\">'POSITIVE'</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9997789263725281</span><span style=\"font-weight: bold\">}]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efcbfa9bdd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(sentiment(\"I hate my life :(\"))\n",
    "print(sentiment(\"I love my life :)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'truth'</span>: <span style=\"color: #008000\">'NEGATIVE'</span>, <span style=\"color: #008000\">'predicted'</span>: <span style=\"color: #008000\">'NEGATIVE'</span>, <span style=\"color: #008000\">'?'</span>: <span style=\"color: #008000\">''</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9998217821121216</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'truth'</span>: <span style=\"color: #008000\">'NEGATIVE'</span>, <span style=\"color: #008000\">'predicted'</span>: <span style=\"color: #008000\">'NEGATIVE'</span>, <span style=\"color: #008000\">'?'</span>: <span style=\"color: #008000\">''</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9997732639312744</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'truth'</span>: <span style=\"color: #008000\">'POSITIVE'</span>, <span style=\"color: #008000\">'predicted'</span>: <span style=\"color: #008000\">'POSITIVE'</span>, <span style=\"color: #008000\">'?'</span>: <span style=\"color: #008000\">''</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9997572898864746</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'truth'</span>: <span style=\"color: #008000\">'NEGATIVE'</span>, <span style=\"color: #008000\">'predicted'</span>: <span style=\"color: #008000\">'NEGATIVE'</span>, <span style=\"color: #008000\">'?'</span>: <span style=\"color: #008000\">''</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9998112320899963</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'truth'</span>: <span style=\"color: #008000\">'POSITIVE'</span>, <span style=\"color: #008000\">'predicted'</span>: <span style=\"color: #008000\">'POSITIVE'</span>, <span style=\"color: #008000\">'?'</span>: <span style=\"color: #008000\">''</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9997597336769104</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'truth'</span>: <span style=\"color: #008000\">'POSITIVE'</span>, <span style=\"color: #008000\">'predicted'</span>: <span style=\"color: #008000\">'POSITIVE'</span>, <span style=\"color: #008000\">'?'</span>: <span style=\"color: #008000\">''</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9995524883270264</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'truth'</span>: <span style=\"color: #008000\">'NEGATIVE'</span>, <span style=\"color: #008000\">'predicted'</span>: <span style=\"color: #008000\">'NEGATIVE'</span>, <span style=\"color: #008000\">'?'</span>: <span style=\"color: #008000\">''</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9997878074645996</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'truth'</span>: <span style=\"color: #008000\">'POSITIVE'</span>, <span style=\"color: #008000\">'predicted'</span>: <span style=\"color: #008000\">'POSITIVE'</span>, <span style=\"color: #008000\">'?'</span>: <span style=\"color: #008000\">''</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9997856020927429</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efcbd3508d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# input-ids and attention-mask from the test-dataloader from earlier.\n",
    "with torch.no_grad():\n",
    "    output = model(inputs, attention_mask=attention_mask)\n",
    "    preds = output[0].cpu()\n",
    "\n",
    "id2label = model.config.id2label\n",
    "scores = np.exp(preds.numpy()) / np.exp(preds.numpy()).sum(-1, keepdims=True)\n",
    "gold_results = [\n",
    "    {\n",
    "        \"truth\": id2label[label.item()],\n",
    "        \"predicted\": id2label[item.argmax()],\n",
    "        \"?\": \"\" if id2label[label.item()] == id2label[item.argmax()] else \"\",\n",
    "        \"score\": item.max().item()\n",
    "    } for item, label in zip(scores, labels)\n",
    "]\n",
    "print(gold_results)  # Our trained model predicted all correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">tensor<span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">0.0002</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efcbcde6e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(F.cross_entropy(output.logits, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[{</span><span style=\"color: #008000\">'label'</span>: <span style=\"color: #008000\">'POSITIVE'</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.7325044870376587</span><span style=\"font-weight: bold\">}]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efcbd2e1890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[{</span><span style=\"color: #008000\">'label'</span>: <span style=\"color: #008000\">'NEGATIVE'</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.6847666501998901</span><span style=\"font-weight: bold\">}]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efcbd271a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Can our model detect the difference between similar texts? Indeed \n",
    "print(sentiment('fuck! life is not worth giving up!'))\n",
    "print(sentiment('fuck! life is not worth it, give up.'))  # tricky, yet correctly predicts its negative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[{</span><span style=\"color: #008000\">'label'</span>: <span style=\"color: #008000\">'POSITIVE'</span>, <span style=\"color: #008000\">'score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9994165301322937</span><span style=\"font-weight: bold\">}]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7efcbd2e1f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(sentiment(\"On a mission to solve NLP, one commit at a time .\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
